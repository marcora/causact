---
title: "causact"
format:
  html:
    toc: true
    df-print: kable
---

## Introduction

There are three languages at the core of any data analysis: narrative, math, and code.

-   **Narrative**: This is the language of your real-world understanding.

-   **Math**: This is the language describing a faithful mathematical representation of your real-world narrative whose solution or output might turn your data into data-driven insight.

-   **Code**: This is the programming language, the code required to generate output that exactly or approximately solves your math problem or generates the desired output.

Using Bayesian inference is the provably best method of combining data with domain knowledge to extract interpretable and insightful results that lead us towards better outcomes.

This is the job of the *business analyst*; to drive better outcomes by compelling actions that are aligned with strategy and informed by data.

![](images/clipboard-2076919182.png)

![](images/clipboard-613416536.png)

The business analyst workflow consists of transforming the real-world into a compact mathematical representation that we can use, along with data, to computationally search for insights. These computational insights must then be translated back into the real-world in such a way that they inspire action which leads to improved outcomes. This is your role: transform the real-world into the math/computer world, extract mathematical/statistical/computational insight, then transform that insight into a compelling real-world call for action.

![](images/clipboard-3434935492.png)

## Representing uncertainty

[Real-world uncertainty]{.smallcaps} makes decision making hard. Conversely, without uncertainty decisions would be easier. For example, if a cafe knew exactly 10 customers would want a bagel, then they could make exactly 10 bagels in the morning; if a factory’s machine could make each part exactly the same, then quality control to ensure the part’s fit could be eliminated; if a customer’s future ability to pay back a loan was known, then a bank’s decision to underwrite the loan would be quite simple.

In this section, we learn to represent our real-world uncertainty (e.g. demand for bagels, quality of a manufacturing process , or risk of loan default) in mathematical and computational terms. We start by defining the ideal mathematical way of representing uncertainty, namely by assigning a *probability distribution* to a *random variable*. Subsequently, we learn to describe our uncertainty in a *random variable* using *representative samples* as a pragmatic computational proxy to this mathematical ideal.

Think of a random variable as a mapping from potential outcomes to numerical values representing the probability we assign to each outcome.

| Outcome | Probability |
|---------|-------------|
| Heads   | 0.5         |
| Tails   | 0.5         |

While the table might be adequate to describe the mapping of coin flip outcomes to probability, as we make more complex models of the real-world, we will want to take advantage of the concise (and often terse) notation that mathematicians would use. In addition, we want to gain fluency in *math world* notation so that we can successfully traverse the bridge between *real world* and *math world*.

Above, a random variable was introduced as a mapping of outcomes to probabilities. And, this is how you should think of it most of the time. However, to start gaining fluency in the math-world definition of a random variable, we will also view this mapping process as not just one mapping, but rather a sequence of two mappings: 1) the first mapping is actually the “true” probability-theory definition of a **random variable** - it maps all possible outcomes to real numbers, and 2) the second mapping, known as a **probability distribution** in probability theory, maps the numbers from the first mapping to real numbers representing how plausibility is allocated across all possible outcomes - we often think of this allocation as assigning probability to each outcome.

The terse math-world representation of a mapping process like this is denoted:

$$
X:\Omega \rightarrow \mathbb{R}
$$

, where you interpret it as “random variable $X$ maps each possible outcome in sample space omega to a real number.”

The second mapping process then assigns a probability distribution to the random variable. By convention, lowercase letters, e.g. $x$, represent actual observed outcomes. We call $x$ the *realization* of random variable $X$ and define the mapping of outcomes to probability for every $x \in X$ (read as $x$ “in” $X$ and interpret it to mean “for each possible realization of random variable $X$”).

In this book, we will use $f$, to denote a function that maps each possible realization of a random variable to its corresponding plausibilty measure and use a subscript to disambiguate which random variable is being referred to when necessary. For the coin flip example:

$$
f_X: X \rightarrow [0,1]
$$

Despite all this fancy notation, for small problems it is sometimes the best course of action to think of a random variable as a lookup table as shown here:

| Outcome | Realization ($x$) | $f(x)$ |
|---------|-------------------|--------|
| Heads   | 1                 | 0.5    |
| Tails   | 0                 | 0.5    |

and where $f(x)$ can be interpreted as the plausability assigned to random variable $X$ taking on the value $x$.

The Bernoulli distribution (or a Bernoulli random variable):

| Outcome | Realization ($x$) | $f(x)$  |
|---------|-------------------|---------|
| Success | 1                 | $\pi$   |
| Failure | 0                 | $1-\pi$ |

With all of this background, we are now equipped to model uncertainty in any observable data that has two outcomes. The way we will represent this uncertainty is using two forms: 1) a graphical model and 2) a statistical model.

```{r setup}
#| output: false
library(tidyverse)
library(ggformula)
library(causact) # causact::install_causact_deps()

theme_set(theme_minimal())

set.seed(123)
```

```{r}
dag_create() |>
  dag_node(
    descr = "Coin flip",
    label = "X") |>
  dag_render(shortLabel = TRUE)
```

$$
\begin{aligned}X &\equiv \textrm{Coin flip outcome with heads}=1 \textrm{  and tails}=0.\\X &\sim \textrm{Bernoulli}(p)\end{aligned}
$$

Instead of working with probability distributions directly as *mathematical* objects, we will most often seek a representative sample and treat them as *computational* objects (i.e. **data**). For modelling a coin flip, the representative sample might simply be a list of $0$ and $1$ generated by someone flipping a coin or by a computer simulating someone flipping a coin.

[Turning a mathematical object into a representative sample using R]{.smallcaps} is quite easy as R can be used to generate random outcomes from just about all well-known probability distributions.

```{r}
rbern(7, p = 0.5)
```

```{r}
set.seed(123) 

# Create dataframe of coinflip observations
numFlips = 50 ## flip the coin 50 times
df = data.frame(
  flipNum = 1:numFlips,
  coinFlip = rbern(n=numFlips,prob=0.5)
  ) %>%
  mutate(headsProportion = cummean(coinFlip))
  
# Plot results
ggplot(df, aes(x = flipNum, y = headsProportion)) + 
  geom_point() +
  geom_line() + 
  geom_hline(yintercept = 0.5, color = "red") +
  ggtitle("Running Proportion of Heads") +
  xlab("Flip Number") + 
  ylab("Proportion of Heads") +
  ylim(c(0,1))
```

$$
\begin{aligned}X_i &\equiv \textrm{If passenger } i \textrm{ shows up, then } X=1 \textrm{. Otherwise, } X = 0 \textrm{. Note: } i \in \{1,2,3\}.\\X_i &\sim \textrm{Bernoulli}(p = 0.85)\\Y &\equiv \textrm{Total number of passengers that show up.}\\Y &= X_1 + X_2 + X_3\end{aligned}
$$

```{r}
numFlights = 1000 ## number of simulated flights
probShow = 0.85 ## probability of passenger showing up

# choose random seed so others can
# replicate results
set.seed(111) 

pass1 = rbern(n = numFlights, prob = probShow)
pass2 = rbern(n = numFlights, prob = probShow)
pass3 = rbern(n = numFlights, prob = probShow)

# create data frame (use tibble to from tidyverse) 
flightDF = tibble(
  simNum = 1:numFlights,
  totalPassengers = pass1 + pass2 + pass3
)

# transform data to give proportion
propDF = flightDF %>% 
  group_by(totalPassengers) %>% 
  summarize(numObserved = n()) %>%
  mutate(proportion = numObserved / sum(numObserved))

# plot data with estimates
ggplot(propDF, 
       aes(x = totalPassengers, y = proportion)) +
  geom_col() +
  geom_text(aes(label = proportion), nudge_y = 0.03)
```

Simulation will always be your friend in the sense that if given enough time, a simulation will always give you results that approximate mathematical exactness. The only problem with this friend is it is sometimes slow to yield representative results. In these cases, sometimes mathematics provides a shortcut. The shortcut we study here is to define a probability distibution.

$$
\begin{aligned}Y &\equiv \textrm{Total number of passengers that show up.}\\Y &\sim \textrm{Binomial}(n = 3, p = 0.85)\end{aligned}
$$

```{r}
# transform data to give proportion
propExactDF = tibble(totalPassengers = 0:3) %>%
  mutate(proportion = 
           dbinom(x = totalPassengers,
                  size = 3,
                  prob = 0.85))

# plot data with estimates
ggplot(propExactDF, aes(x = totalPassengers, 
                        y = proportion)) +
  geom_col() +
  geom_text(aes(label = proportion), 
            nudge_y = 0.03)
```

The above code is both simpler and faster than the approximation code run earlier. In addition, it gives exact results. Hence, when we can take mathematical shortcuts, we will to save time and reduce the uncertainty in our results introduced by approximation error.

Our representation of uncertainty takes place in three worlds: 1) the real-world - we use graphical models (i.e. ovals) to convey the story of uncertainty, 2) the math-world - we use statistical models to rigorously define how random outcomes are generated, and 3) the computation-world - we use R functions to answer questions about exact distributions and representative samples to answer questions when the exact distribution is unobtainable.

## Joint distributions tell you everything

The most complete method of reasoning about sets of random variables is by having a *joint probability distribution*. A joint probability distribution, , assigns a probability value to all possible assignments or realizations of sets of random variables. The goal of this section is to 1) introduce you to the notation of joint probability distributions and 2) convince you that if you are given a joint probability distribution, then you would be able to answer some very useful questions using probability.

### Joint distributions

### Marginal distributions

### Conditional distributions

### Limitations of joint distributions

[Why don’t we just use joint probability distributions all the time?]{.smallcaps} Despite the expressive power of having a joint probability distribution, they are not that easy to directly construct due to the *curse of dimensionality*. As the number of random variables being considered in a dataset grows, the number of potential probability assignments grows too. Even in the era of big data, this curse of dimensionality still exists.Generally speaking, an exponential increase is required in the size of the dataset as each new descriptive feature is added.

Let’s assume we have $n$ random variables with each having $k$ values. Thus, the joint distribution requires $k^n$ probabilites. Even if $k=2$ and $n=34$, this leads to 17,179,869,184 possibilities (over 17 billion). To make this concrete, a typical car purchase decision might easily look at 34 different variables (e.g. make, model, color, style, financing, etc.). So, to model this decision would require a very large joint distribution which actually dwarfs the amount of data that is available. As a point of comparison, well under 100 million motor vehicles were sold worldwide in 2019 - i.e. less than one data point per possible combination of features. Despite this “curse”, we will learn to get around it with more compact representations of joint distributions. These representations will require less data, but will still yield the power to answer queries of interest; just as if we had access to the full joint distribution.

## Graphical models tell joint distribution stories

Graphical models serve as compact representations of joint probability distributions.

It’s okay to not draw a perfect model when you are first attacking a problem.

```{mermaid}
graph TD
    X[ X: It is raining ]
    Y[ Y: The curb is wet ]
    X --> Y
```

The diagram above is what mathematicians and computer scientists call a *graph*. To them, a *graph* is a set of related objects where the objects are called *nodes* and any pair of related nodes are known as an *edge*. For our purposes, a *node* is a visual depiction of a random variable (i.e. an oval) and the presence of a visible *edge* indicates a relationship between the connected random variables.

Our first vetting should be to ensure that nodes can be modelled as a random variable with each node representing a mapping of real-world outcomes to numerical values (see the “Representing uncertainty” section above).

Any variable we include in our models needs to be clearly defined and fulfill the requirements of a random variable; afterall, this is our key technique for representing the *real-world* in mathematical terms.

Mathematically, our goal is to have a joint distribution over the random variables of interest. Once we have that, we can answer any probability query we might have using marginal and conditional distributions (see the “Joint distributions tell you everything” section above).

For all but very simple models like the one above, a tabular representation of a joint distribution becomes unmanageable (computationally, cognitively, and statistically).

To overcome this, we use a different, more-compact structure - called a *Bayesian Network* (BN). Bayesian networks are compressed, easier-to-specify recipes for generating a full joint distribution. So, what is a BN? It is a type of *graph* (i.e. nodes and edges), specifically a *directed acyclic graph* (DAG), with the following requirements:

1.  All nodes represent random variables. They are drawn using ovals. By convention, a constant is also considered a random variable.

2.  All edges are pairs of random variables with a specified direction of ordering. By convention, the direction is from parent node to child node. While not always true, it is usually good to have edges reflecting a causal ordering. Edges are drawn using arrows where the tail originates from the parent and the tip points to a child.

3.  Edges are uni-directional, they must only flow in one direction between any two nodes (i.e. *directed*).

4.  The graph is *acyclic* meaning there are no cycles. In other words, if you were to put your finger on any node and trace a path following the direction of the edges, you would not be able to return to the starting node.

5.  Any child node’s probability distribution will be expressed as conditional solely on its parents’ values, i.e. $P(\text{child}\mid \text{parent(s)})$; this assumption is what enables more compact representations of joint distributions.

The one edge, $Y \rightarrow X$, means that our uncertainty in $X$ is measured using a probability function conditional on its parent - i.e. $P(X|Y)$. Since there are no edges leading into $Y$, it has no parents, its probability distribution is $P(Y)$ . With those two probabilities in place, we can recover the joint distribution, $P(X,Y)$, based on the definition of conditional probability $P(X,Y) = P(Y) \times P(X|Y)$.

If there are no edges between $X$ and $Y$, then the joint distribution is recovered via $P(X,Y)=P(X)\cdot P(Y)$. In this case, the two random variables are independent and that is not a model structure consistent with the scenario we are exploring. If the ordering of nodes for $X$ and $Y$ are reversed such that $Y$ is the parent of $X$, then the joint distribution would be recovered via $P(X,Y)=P(Y)\cdot P(X\mid Y)$. This math is not consistent with the story we are trying to tell. The story is that rain causes the curb to be wet, not the other way around.

The general rule for a probabilistic graphical model is that its joint distribution can be factored using the chain rule formula for DAGs where $P(X_1, X_2, \ldots, X_n) = \prod_I P(X_i|Parents(X_i))$. Hence, to model any one random variable, we only have to model its relationship to its parents instead of modelling its relationship to all of the random variables included in the model.

See mathematicalmonk’s youtube video on how joint distributions are compactly represented using DAGs here: <https://youtu.be/3XysEf3IQN4>.
